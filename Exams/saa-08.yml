questions:
- id: q350
  type: multiple_choice
  question: |
    A company uses a 100 GB Amazon RDS for Microsoft SQL Server Single-AZ DB instance in the us-east-1 Region to store customer transactions. The company needs high availability and automatic recovery for the DB instance.
    The company must also run reports on the RDS database several times a year. The report process causes transactions to take longer than usual to post to the customers’ accounts. The company needs a solution that will improve the performance of the report process.
    Which combination of steps will meet these requirements? (Choose two.)
  options:
    - text: Modify the DB instance from a Single-AZ DB instance to a Multi-AZ deployment.
      is_correct: true
    - text: Create a read replica of the DB instance in a different Availability Zone. Point all requests for reports to the read replica.
      is_correct: true
    - text: Use Amazon ElastiCache to cache the report results.
      is_correct: false
    - text: Vertical scale the DB instance to a larger instance size during the reporting period.
      is_correct: false
    - text: Enable Multi-Region replication for the RDS instance.
      is_correct: false
  explanation: |
    Correct: Multi-AZ provides high availability and automatic failover. Read replicas offload read-heavy reporting workloads from the primary instance, preventing performance degradation for write transactions.
    Incorrect:
      - ElastiCache helps with frequent small reads, but reporting usually involves large, infrequent analytical queries where caching is less effective.
      - Scaling the instance vertically improves performance but doesn't solve the contention between transactions and reports as effectively as a replica.
      - Multi-Region replication is more complex and expensive than needed for this scenario.
  diagram: |
    graph TD
      A[RDS Primary Instance] -->|Writes| B[Multi-AZ Standby]
      A -->|Reads| C[Read Replica]
      C -->|Reports| D[Application]

- id: q351
  type: multiple_choice
  question: |
    A company is moving its data management application to AWS. The company wants to transition to an event-driven architecture that is distributed, uses serverless concepts, and minimizes operational overhead.
    Which solution will meet these requirements?
  options:
    - text: Build out the workflow in AWS Step Functions. Use Step Functions to create a state machine to invoke AWS Lambda functions to process the workflow steps.
      is_correct: true
    - text: Use Amazon EC2 instances to run a custom workflow engine and call SQS queues.
      is_correct: false
    - text: Use an Amazon EMR cluster to process the different aspects of the workflow.
      is_correct: false
    - text: Implement an AWS Glue workflow to trigger various AWS Batch jobs.
      is_correct: false
  explanation: |
    Correct: AWS Step Functions is a serverless orchestrator that manages state and retries with minimal overhead, integrating perfectly with Lambda for an event-driven design.
    Incorrect:
      - EC2 instances increase operational overhead for management and patching.
      - EMR is for big data processing, not general application workflow orchestration.
      - AWS Glue is an ETL service, not a general-purpose application event-driven orchestrator.
  diagram: |
    graph TD
      A[Event] -->|Trigger| B[AWS Step Functions]
      B -->|Invoke| C[AWS Lambda]
      C -->|Process| D[Workflow Steps]

- id: q352
  type: multiple_choice
  question: |
    A company is designing the network for an online multi-player game using the UDP protocol in eight AWS Regions. The architecture needs to minimize latency and packet loss for global users.
    Which solution will meet these requirements?
  options:
    - text: Set up AWS Global Accelerator with UDP listeners and endpoint groups in each Region.
      is_correct: true
    - text: Use Amazon CloudFront with an custom origin for each Region.
      is_correct: false
    - text: Configure Route 53 with a Latency routing policy pointing to the public IPs of the game servers.
      is_correct: false
    - text: Use an AWS Transit Gateway to connect all Regions and route traffic internally.
      is_correct: false
  explanation: |
    Correct: AWS Global Accelerator supports UDP and uses the AWS global private network to route traffic, reducing latency and jitter compared to the public internet.
    Incorrect:
      - CloudFront is primarily for HTTP/HTTPS content and does not support general UDP traffic.
      - Route 53 Latency routing still relies on the public internet for the actual packet transit.
      - Transit Gateway connects VPCs but does not provide an entry point for end-users over the internet.
  diagram: |
    graph TD
      A[Global Users] -->|UDP| B[AWS Global Accelerator]
      B -->|Route| C[Endpoint Groups in Regions]
      C -->|Low Latency| D[Game Servers]

- id: q353
  type: multiple_choice
  question: |
    A company hosts a three-tier web application using a self-managed MySQL database on an EC2 instance with a 1 TB io2 EBS volume. Peak traffic is 1,000 IOPS. They want to move to a fully managed, highly available solution that can handle 2,000 IOPS (double the current peak) cost-effectively.
    Which solution will meet these requirements?
  options:
    - text: Use a Multi-AZ deployment of an Amazon RDS for MySQL DB instance with a General Purpose SSD (gp2) EBS volume.
      is_correct: true
    - text: Migrate the database to an Amazon Aurora Cluster with a single writer instance.
      is_correct: false
    - text: Use a Single-AZ Amazon RDS for MySQL with a Provisioned IOPS SSD (io1) volume.
      is_correct: false
    - text: Use Amazon RDS for MySQL in a Multi-AZ deployment with a 1 TB io2 volume.
      is_correct: false
  explanation: |
    Correct: RDS Multi-AZ provides high availability. A gp2 volume of 1 TB provides a baseline of 3,000 IOPS, which exceeds the 2,000 IOPS requirement and is more cost-effective than io2.
    Incorrect:
      - Aurora is highly available but typically more expensive than RDS MySQL with gp2 for this specific scale.
      - Single-AZ does not meet the "highly available and fault tolerant" requirement.
      - Using io2 is unnecessary and more expensive since gp2 can handle the requested IOPS.
  diagram: |
    graph TD
      A[Application] -->|Queries| B[RDS Multi-AZ MySQL]
      B -->|gp2 Volume| C[High IOPS]

- id: q354
  type: multiple_choice
  question: |
    A serverless application using API Gateway, Lambda, and RDS PostgreSQL experiences database connection timeouts during peak traffic. The company needs to reduce failures with the least amount of code change.
    What should a solutions architect do?
  options:
    - text: Enable RDS Proxy on the RDS DB instance.
      is_correct: true
    - text: Migrate the database to Amazon DynamoDB.
      is_correct: false
    - text: Increase the memory of the Lambda functions to allow for more connections.
      is_correct: false
    - text: Configure the Lambda functions to use a singleton connection pattern.
      is_correct: false
  explanation: |
    Correct: RDS Proxy pools database connections, which is essential for Lambda functions that scale rapidly and might otherwise exhaust database connection limits.
    Incorrect:
      - Migrating to DynamoDB requires a complete rewrite of the application code.
      - Increasing Lambda memory doesn't solve the backend database connection limit.
      - A singleton pattern in Lambda is difficult to implement due to its stateless nature and doesn't solve the aggregate connection spike.
  diagram: |
    graph TD
      A[API Gateway] -->|Invoke| B[Lambda]
      B -->|Connect| C[RDS Proxy]
      C -->|Pool| D[RDS PostgreSQL]

- id: q355
  type: multiple_choice
  question: |
    A company runs a CPU-intensive batch job (64 vCPU, 512 GiB RAM) every hour that takes 15 minutes.
    Which solution will run the job with the LEAST operational overhead?
  options:
    - text: Use AWS Batch on Amazon EC2.
      is_correct: true
    - text: Run the task as an AWS Lambda function with maximum resource allocation.
      is_correct: false
    - text: Schedule a cron job on a persistent t3.large EC2 instance.
      is_correct: false
    - text: Create an Amazon EMR cluster that scales up and down every hour.
      is_correct: false
  explanation: |
    Correct: AWS Batch handles the provisioning and scaling of EC2 instances based on the job requirements, making it ideal for intensive batch processing.
    Incorrect:
      - Lambda has a maximum limit of 6 vCPUs and 10 GB of RAM, which is far below the 64 vCPU/512 GiB requirement.
      - A t3.large instance is too small and a persistent instance for a 15-minute job is not cost-effective.
      - EMR is designed for Hadoop/Spark workloads, not general-purpose CPU-intensive batch jobs.
  diagram: |
    graph TD
      A[Batch Job] -->|Submit| B[AWS Batch]
      B -->|Provision| C[EC2 Instances]
      C -->|Run| D[CPU-Intensive Task]

- id: q356
  type: multiple_choice
  question: |
    75% of data in S3 Standard is rarely accessed after 30 days. The data must remain immediately accessible with high availability.
    Which storage solution minimizes costs?
  options:
    - text: Move the data objects to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days.
      is_correct: true
    - text: Move the data objects to S3 Glacier Flexible Retrieval after 30 days.
      is_correct: false
    - text: Use an S3 Lifecycle policy to move the data to S3 One Zone-IA after 30 days.
      is_correct: false
    - text: Enable S3 Intelligent-Tiering immediately for all objects.
      is_correct: false
  explanation: |
    Correct: S3 Standard-IA offers the same millisecond access as S3 Standard but at a lower storage price for data not accessed frequently, while maintaining high availability across multiple zones.
    Incorrect:
      - S3 Glacier does not provide "immediate" access (retrieval takes minutes to hours).
      - One Zone-IA has lower resiliency (data lost if AZ fails).
      - Intelligent-Tiering is good, but moving specifically to IA after a known 30-day threshold is the standard cost-optimization answer.
  diagram: |
    graph TD
      A[S3 Standard] -->|30 Days| B[S3 Standard-IA]
      B -->|Immediate Access| C[High Availability]

- id: q357
  type: multiple_choice
  question: |
    A gaming company needs a highly available storage solution for Windows EC2 instances hosting a dynamic application with static files and server-side code.
    Which combination of steps should be taken? (Choose two.)
  options:
    - text: Store the static files on Amazon S3. Use Amazon CloudFront to cache objects at the edge.
      is_correct: true
    - text: Store the server-side code on Amazon FSx for Windows File Server. Mount the volume on each EC2 instance.
      is_correct: true
    - text: Store the server-side code on Amazon Elastic Block Store (EBS) Multi-Attach volumes.
      is_correct: false
    - text: Use Amazon Elastic File System (EFS) to store the server-side code.
      is_correct: false
    - text: Host the dynamic application directly from an S3 bucket with static website hosting.
      is_correct: false
  explanation: |
    Correct: S3 with CloudFront is the best practice for static assets. FSx for Windows is the native managed file system for Windows instances to share code and files via SMB.
    Incorrect:
      - EBS Multi-Attach is for specific cluster-aware applications on Linux/Windows and is complex.
      - EFS is a Linux-native file system (NFS), while the requirement is for Windows instances.
      - S3 static hosting cannot execute server-side code (Windows/dynamic code).
  diagram: |
    graph TD
      A[EC2 Instances] -->|Static Files| B[S3 + CloudFront]
      A -->|Server Code| C[FSx for Windows File Server]

- id: q358
  type: multiple_choice
  question: |
    A company wants to resize a billion images stored in S3 dynamically and serve appropriate formats via CloudFront with the LEAST operational overhead.
    Which solution will meet these requirements?
  options:
    - text: Use a Lambda@Edge function with an external image management library associated with CloudFront.
      is_correct: true
    - text: Set up an Auto Scaling group of EC2 instances to process and resize images.
      is_correct: false
    - text: Use S3 Batch Operations to pre-resize all images into different formats.
      is_correct: false
    - text: Trigger an AWS Step Functions workflow every time an image is requested from S3.
      is_correct: false
  explanation: |
    Correct: Lambda@Edge allows image manipulation at the edge, reducing latency and avoiding the need to manage a fleet of servers or pre-process billions of images.
    Incorrect:
      - EC2 fleets increase operational overhead.
      - S3 Batch Operations would be extremely expensive for a billion images and would not be "dynamic" for new requests.
      - Step Functions is too slow for real-time image serving.
  diagram: |
    graph TD
      A[User Request] -->|CloudFront| B[Lambda@Edge]
      B -->|Resize| C[S3 Images]
      C -->|Serve| D[Optimized Format]

- id: q359
  type: multiple_choice
  question: |
    A hospital must ensure S3 patient records are encrypted in transit and at rest. The hospital team must manage the encryption keys for data at rest.
    Which solution meets these requirements?
  options:
    - text: Use the aws:SecureTransport condition on S3 bucket policies. Configure default encryption to use SSE-KMS with customer managed keys.
      is_correct: true
    - text: Enable SSE-S3 on the bucket and use a VPN for transit.
      is_correct: false
    - text: Use AWS KMS with SSE-KMS, but allow AWS to manage the default S3 key.
      is_correct: false
    - text: Encrypt the data using a client-side tool before uploading to S3 over HTTP.
      is_correct: false
  explanation: |
    Correct: "aws:SecureTransport: false" in a deny policy enforces HTTPS (encryption in transit). SSE-KMS with a customer managed key allows the team to manage the key.
    Incorrect:
      - SSE-S3 means AWS manages the keys, not the hospital team.
      - Default KMS keys (aws/s3) are managed by AWS, not the customer.
      - Uploading over HTTP is insecure, even if the data is encrypted; the standard is to enforce TLS.
  diagram: |
    graph TD
      A[Hospital] -->|HTTPS| B[S3 Bucket]
      B -->|SSE-KMS| C[Customer Managed Key]

- id: q360
  type: multiple_choice
  question: |
    Two REST APIs in the same VPC communicate over the internet. How can they communicate through the VPC with the FEWEST code changes?
  options:
    - text: Use an interface endpoint for API Gateway.
      is_correct: true
    - text: Set up a NAT Gateway in the private subnet.
      is_correct: false
    - text: Use a VPC peering connection between the API Gateway service and the VPC.
      is_correct: false
    - text: Update the code to use the private IP addresses of the API Gateway endpoints.
      is_correct: false
  explanation: |
    Correct: An Interface VPC Endpoint (powered by PrivateLink) allows the VPC instances to reach the API Gateway service using private IP addresses without traffic leaving the AWS network.
    Incorrect:
      - NAT Gateway allows private instances to reach the internet, it doesn't keep traffic private if they are using public endpoints.
      - VPC Peering is for connecting two VPCs, not for connecting a VPC to a managed service.
      - API Gateway endpoints do not have fixed "private IPs" you can hardcode without an endpoint.
  diagram: |
    graph TD
      A[VPC Instances] -->|PrivateLink| B[API Gateway Endpoint]
      B -->|Private| C[API Gateway]

- id: q361
  type: multiple_choice
  question: |
    A company needs a highly available, POSIX-compliant storage layer that is shareable across multiple AZs. Data is frequent for 30 days, then infrequent.
    Which solution is MOST cost-effective?
  options:
    - text: Use the Amazon Elastic File System (Amazon EFS) Standard storage class. Create a lifecycle management policy to move infrequently accessed data to EFS Standard-Infrequent Access (EFS Standard-IA).
      is_correct: true
    - text: Use Amazon EBS volumes with Multi-Attach enabled across all instances.
      is_correct: false
    - text: Use Amazon S3 with an S3 File Gateway to provide POSIX compatibility.
      is_correct: false
    - text: Deploy a clustered file system like Lustre on EC2 instances using EBS.
      is_correct: false
  explanation: |
    Correct: EFS is natively POSIX-compliant, shareable across multiple instances/AZs, and its Lifecycle Management feature automatically optimizes costs for older data.
    Incorrect:
      - EBS Multi-Attach is limited to a single AZ and requires specific cluster-aware file systems.
      - S3 File Gateway provides an interface but isn't as natively POSIX-compliant for complex application logic as EFS.
      - Self-managed clusters on EC2 increase operational overhead significantly.
  diagram: |
    graph TD
      A[Multi-AZ Instances] -->|POSIX| B[EFS Standard]
      B -->|Lifecycle| C[EFS Standard-IA]

- id: q362
  type: multiple_choice
  question: |
    A payment system requires messages for a specific payment ID to be processed in the order they were sent.
    Which actions should a solutions architect take? (Choose two.)
  options:
    - text: Write the messages to an Amazon Kinesis data stream with the payment ID as the partition key.
      is_correct: true
    - text: Write the messages to an Amazon SQS FIFO queue and use the payment ID as the Message Group ID.
      is_correct: true
    - text: Use an Amazon SNS standard topic to fan out messages to multiple SQS queues.
      is_correct: false
    - text: Use an Amazon SQS standard queue with a visibility timeout set to 0.
      is_correct: false
    - text: Use an AWS Lambda function to sort the messages in an S3 bucket.
      is_correct: false
  explanation: |
    Correct: Kinesis ensures order within a shard based on the partition key. SQS FIFO ensures order within a message group.
    Incorrect:
      - Standard SNS/SQS does not guarantee ordering.
      - S3 sorting is a post-processing step and doesn't solve the real-time ingestion order requirement.
    diagram: |
      graph TD
        A[Messages] -->|Partition Key| B[Kinesis Data Stream]
        A -->|Group ID| C[SQS FIFO]

- id: q363
  type: multiple_choice
  question: |
    A game system needs to send events to leaderboard, matchmaking, and authentication services concurrently while guaranteeing the order of events.
    Which solution will meet these requirements?
  options:
    - text: Amazon Simple Notification Service (Amazon SNS) FIFO topics.
      is_correct: true
    - text: Amazon SQS standard queues with fan-out.
      is_correct: false
    - text: Amazon Kinesis Data Firehose.
      is_correct: false
    - text: AWS Step Functions with a Parallel state.
      is_correct: false
  explanation: |
    Correct: SNS FIFO topics allow for fan-out (sending to multiple subscribers) while maintaining strict message ordering and deduplication.
    Incorrect:
      - Standard SQS does not guarantee order.
      - Kinesis Firehose is for loading data into S3/Redshift, not real-time event distribution to microservices.
      - Step Functions Parallel state doesn't natively guarantee the order of external events being ingested.
    diagram: |
      graph TD
        A[Game Events] -->|FIFO| B[SNS FIFO Topic]
        B -->|Fan-out| C[Leaderboard Service]
        B -->|Fan-out| D[Matchmaking Service]
        B -->|Fan-out| E[Authentication Service]

- id: q364
  type: multiple_choice
  question: |
    A hospital uses SQS and SNS. Data must be encrypted at rest and in transit, with access restricted to authorized personnel.
    Which combination of steps should be taken? (Choose two.)
  options:
    - text: Turn on SSE on SNS components using a KMS customer managed key and apply a restrictive key policy.
      is_correct: true
    - text: Turn on SSE on SQS components using a KMS customer managed key and enforce TLS via a queue policy.
      is_correct: false
    - text: Use an IAM policy to restrict S3 bucket access.
      is_correct: false
    - text: Configure SNS and SQS to use the default AWS managed key (aws/sns and aws/sqs).
      is_correct: false
    - text: Turn on server-side encryption on the SQS components by using an AWS KMS customer managed key. Apply a key policy and set a condition in the queue policy to allow only encrypted connections over TLS.
      is_correct: true
  explanation: |
    Correct: Using customer managed keys (CMK) allows the hospital to control the key policy (authorized principals). TLS enforcement in the SQS policy handles transit encryption.
    Incorrect:
      - AWS managed keys do not allow the customer to modify the key policy for specific personnel.
      - IAM policies on S3 are irrelevant for SQS/SNS infrastructure.
    diagram: |
      graph TD
        A[Hospital] -->|TLS| B[SNS with SSE-KMS]
        A -->|TLS| C[SQS with SSE-KMS]

- id: q365
  type: multiple_choice
  question: |
    A company needs to restore an RDS database to its state from 5 minutes before an accident, within the last 30 days.
    Which feature should be used?
  options:
    - text: Automated backups.
      is_correct: true
    - text: RDS Read Replicas.
      is_correct: false
    - text: Manual snapshots.
      is_correct: false
    - text: Multi-AZ failover.
      is_correct: false
  explanation: |
    Correct: RDS Automated Backups allow Point-in-Time Recovery (PITR) to any second within the retention period (up to 35 days).
    Incorrect:
      - Read Replicas are for scaling reads, not for rolling back data changes.
      - Manual snapshots are point-in-time but only at the moment they were taken, not every 5 minutes.
      - Multi-AZ is for HA; the error (editing a table) would be replicated to the standby immediately.
  diagram: |
    graph TD
      A[RDS Instance] -->|Automated Backups| B[Point-in-Time Restore]

- id: q367
  type: multiple_choice
  question: |
    A company must host a UDP-based application on-premises but wants to improve performance and availability using AWS.
    What should a solutions architect do?
  options:
    - text: Configure Network Load Balancers (NLBs) in AWS Regions to address the on-premises endpoints. Use AWS Global Accelerator and register the NLBs as endpoints.
      is_correct: true
    - text: Move the application to EC2 instances to meet compliance.
      is_correct: false
    - text: Use Amazon CloudFront to cache the UDP traffic.
      is_correct: false
    - text: Use Route 53 with an IP-based routing policy.
      is_correct: false
  explanation: |
    Correct: Global Accelerator provides a high-performance entry point into the AWS network. NLBs can point to on-premises IP addresses via Direct Connect or VPN, keeping the application on-premises while using AWS's network edge.
    Incorrect:
      - Moving to EC2 violates the "must be hosted on-premises" requirement.
      - CloudFront does not support UDP.
      - Route 53 routing doesn't improve the network transit performance as well as Global Accelerator.

- id: q368
  type: multiple_choice
  question: |
    A solutions architect wants to enforce complexity requirements and rotation periods for all new IAM user passwords.
    What should be done?
  options:
    - text: Set an overall password policy for the entire AWS account.
      is_correct: true
    - text: Create an IAM group for new users with a password-restricted policy.
      is_correct: false
    - text: Use an AWS Config rule to delete users that don't comply.
      is_correct: false
    - text: Use an AWS Lambda function to check password strength during user creation.
      is_correct: false
  explanation: |
    Correct: The IAM password policy is an account-level setting that enforces rules (length, characters, rotation) for all IAM users.
    Incorrect:
      - Groups cannot enforce password complexity; only the account-wide policy can.
      - AWS Config can detect issues but doesn't prevent them as natively as the password policy.
    diagram: |
      graph TD
        A[IAM Users] -->|Enforce| B[Account Password Policy]
        B -->|Strength| C[Password Policy Rules]

- id: q369
  type: multiple_choice
  question: |
    An EC2 instance runs several 1-hour tasks with no common language. Scalability and performance are concerns.
    Which solution has the LEAST operational overhead?
  options:
    - text: Use AWS Batch to run the tasks as jobs and schedule them via Amazon EventBridge.
      is_correct: true
    - text: Rewrite all tasks in Node.js and run them on AWS Lambda.
      is_correct: false
    - text: Use an Amazon EKS cluster with Fargate to orchestrate the tasks.
      is_correct: false
    - text: Use a larger EC2 instance and write a custom shell script to manage the load.
      is_correct: false
  explanation: |
    Correct: AWS Batch is designed for exactly this: running various jobs in containers with different requirements, managing the scaling and scheduling automatically.
    Incorrect:
      - Lambda has a maximum limit of 6 vCPUs and 10 GB of RAM, which is far below the 64 vCPU/512 GiB requirement.
      - EKS with Fargate is more complex to manage than AWS Batch for simple scheduled tasks.
      - Larger instances don't solve the scalability or isolation concerns.
  diagram: |
    graph TD
      A[Tasks] -->|Schedule| B[EventBridge]
      B -->|Trigger| C[AWS Batch]
      C -->|Run| D[EC2 Jobs]

- id: q370
  type: multiple_choice
  question: |
    EC2 instances in private subnets need to reach a license server on the internet. The solution must minimize maintenance.
    Which solution meets this?
  options:
    - text: Provision a NAT gateway in a public subnet and update private route tables.
      is_correct: true
    - text: Assign a public IP to each instance in the private subnet.
      is_correct: false
    - text: Deploy a NAT instance in a public subnet and manage the routing.
      is_correct: false
    - text: Use a VPC peering connection to a VPC that has an internet gateway.
      is_correct: false
  explanation: |
    Correct: NAT Gateway is a managed AWS service that provides internet access to private instances with high availability and no management overhead.
    Incorrect:
      - Assigning public IPs doesn't work in a private subnet (no route to IGW).
      - NAT instances are self-managed and require more maintenance than a NAT gateway.
      - VPC peering doesn't support transitive routing to an IGW.
  diagram: |
    graph TD
      A[Private Subnet EC2] -->|NAT Gateway| B[Public Subnet]
      B -->|Internet| C[License Server]

- id: q371
  type: multiple_choice
  question: |
    An EKS cluster with a managed node group must encrypt all data at rest using a customer managed KMS key with LEAST overhead.
    Which actions meet this? (Choose two.)
  options:
    - text: Enable EBS encryption by default in the AWS Region and select the customer managed key.
      is_correct: true
    - text: Create an IAM role with permission to use the key and associate it with the EKS cluster.
      is_correct: true
    - text: Manually encrypt each EBS volume using the AWS CLI.
      is_correct: false
    - text: Use an S3 bucket for all EKS storage and enable bucket encryption.
      is_correct: false
    - text: Install a third-party encryption tool on each EKS node.
      is_correct: false
  explanation: |
    Correct: Enabling EBS encryption by default at the regional level ensures all volumes (including EKS managed nodes) are encrypted automatically. The IAM role allows EKS to manage those resources.
    Incorrect:
      - Manual encryption is high overhead.
      - EKS nodes use EBS for the root volume and local storage, not S3.
    diagram: |
      graph TD
        A[EKS Cluster] -->|IAM Role| B[KMS Customer Key]
        B -->|Encrypt| C[EBS Volumes]

- id: q372
  type: multiple_choice
  question: |
    A company migrating an Oracle database needs to store millions of high-res GIS images. Images are updated frequently during disasters.
    Which solution is MOST cost-effective and scalable?
  options:
    - text: Store the images in Amazon S3 and store the metadata/URLs in an Amazon RDS Multi-AZ Oracle instance.
      is_correct: true
    - text: Store the images as BLOBs directly in the Oracle database.
      is_correct: false
    - text: Use Amazon DynamoDB to store the images and the geographic codes.
      is_correct: false
    - text: Use an Amazon EFS volume mounted on EC2 instances running Oracle.
      is_correct: false
  explanation: |
    Correct: Storing large binary files (images) in S3 is significantly cheaper and more scalable than storing them in a relational database. RDS handles the structured metadata.
    Incorrect:
      - BLOBs in a database increase storage costs and hurt performance.
      - DynamoDB has a 400KB item limit; high-res GIS images will exceed this.
  diagram: |
    graph TD
      A[Oracle RDS] -->|Metadata| B[S3 Images]

- id: q373
  type: multiple_choice
  question: |
    A company collects trillions of IoT objects. Data is used daily for 30 days, then 4 times a year for 12 months, then archived.
    Which storage solution is MOST cost-effective?
  options:
    - text: Use S3 Standard. Transition to S3 Standard-IA after 30 days, and to S3 Glacier Deep Archive after 1 year.
      is_correct: true
    - text: Use S3 Intelligent-Tiering for all data.
      is_correct: false
    - text: Use S3 Standard for 30 days, then move to S3 One Zone-IA for the rest of the year.
      is_correct: false
    - text: Keep all data in S3 Standard to ensure minimal delay.
      is_correct: false
  explanation: |
    Correct: This lifecycle covers all requirements: Standard for frequent daily use, IA for the infrequent quarterly analysis (which still requires low latency), and Deep Archive for long-term storage.
    Incorrect:
      - Intelligent-Tiering has a monitoring fee per object, which is expensive for "trillions" of objects.
      - One Zone-IA risks data loss, which is usually not acceptable for historical data.
  diagram: |
    graph TD
      A[S3 Standard] -->|30 Days| B[S3 Standard-IA]
      B -->|1 Year| C[S3 Glacier Deep Archive]

- id: q374
  type: multiple_choice
  question: |
    Three VPCs must communicate with each other and send hundreds of GBs of data daily to an on-premises data center via a latency-sensitive connection.
    Which solution is MOST cost-effective?
  options:
    - text: Set up one AWS Direct Connect connection. Create a transit gateway and attach each VPC to it.
      is_correct: true
    - text: Set up a Site-to-Site VPN for each VPC to the data center.
      is_correct: false
    - text: Use VPC Peering between all VPCs and a separate Direct Connect for each.
      is_correct: false
    - text: Use a Transit Gateway with a VPN connection.
      is_correct: false
  explanation: |
    Correct: Direct Connect handles the latency-sensitive and high-volume data requirement better than VPN. Transit Gateway simplifies the many-to-one connectivity between VPCs and the on-premises site.
    Incorrect:
      - VPN is over the public internet and not suitable for latency-sensitive, high-volume data (hundreds of GBs daily).
      - Multiple Direct Connects are more expensive than one connection used with a Transit Gateway.
    diagram: |
      graph TD
        A[VPC1] -->|Transit Gateway| B[Direct Connect]
        C[VPC2] -->|Transit Gateway| B
        D[VPC3] -->|Transit Gateway| B
        B -->|On-premises| E[Data Center]

- id: q375
  type: multiple_choice
  question: |
    A serverless application needs to combine multiple Lambda functions, include manual approvals, and orchestrate services on EC2 and on-premises.
    Which solution has the LEAST operational overhead?
  options:
    - text: Use AWS Step Functions to build the application.
      is_correct: true
    - text: Use Amazon SQS to chain the Lambda functions together.
      is_correct: false
    - text: Write a master Lambda function that calls all other functions and waits for manual input.
      is_correct: false
    - text: Use AWS Glue Workflows.
      is_correct: false
  explanation: |
    Correct: Step Functions natively supports "Activities" or "Task Tokens" for manual approvals and can orchestrate any AWS or on-premises service.
    Incorrect:
      - SQS doesn't handle manual approvals or complex state orchestration easily.
      - A "master" Lambda would time out (15-min limit) while waiting for manual approvals.

- id: q376
  type: multiple_choice
  question: |
    Serverless applications cause database connection rejection errors on an RDS MySQL instance during demand spikes.
    Which solution has the LEAST operational overhead?
  options:
    - text: Create a proxy in RDS Proxy and configure applications to use it.
      is_correct: true
    - text: Scale the RDS instance to a larger size.
      is_correct: false
    - text: Use Amazon ElastiCache to reduce the number of queries.
      is_correct: false
    - text: Implement a retry logic with exponential backoff in the application code.
      is_correct: false
  explanation: |
    Correct: RDS Proxy is a managed service that handles connection pooling, preventing the database from being overwhelmed by too many simultaneous serverless connections.
    Incorrect:
      - Scaling doesn't solve the connection limit efficiently.
      - ElastiCache doesn't solve the connection exhaustion during the initial login/connect phase.
      - Retry logic helps but doesn't prevent the errors from occurring under high load.
    diagram: |
      graph TD
        A[Serverless Apps] -->|RDS Proxy| B[RDS MySQL]
        B -->|Pool Connections| C[Stable Access]

- id: q377
  type: multiple_choice
  question: |
    A company needs to ensure all EC2 instances in an Auto Scaling group send reports to an auditing system as soon as they are launched and before they are terminated.
    Which solution is MOST efficient?
  options:
    - text: Use EC2 Auto Scaling lifecycle hooks to run a custom script during launch and termination.
      is_correct: true
    - text: Use a cron job on the instances to send reports every minute.
      is_correct: false
    - text: Use CloudWatch Events (EventBridge) to trigger a Lambda function on instance state changes.
      is_correct: false
    - text: Install the CloudWatch agent on all instances.
      is_correct: false
  explanation: |
    Correct: Lifecycle hooks pause the instance state (e.g., Pending:Wait or Terminating:Wait), allowing a script to finish its task (like auditing) before the instance continues.
    Incorrect:
      - A cron job might miss the final seconds of an instance's life before termination.
      - EventBridge triggers *after* the state change, which might be too late to collect internal data from a terminated instance.
    diagram: |
      graph TD
        A[ASG Launch] -->|Lifecycle Hook| B[Custom Script]
        B -->|Send Report| C[Auditing System]
        D[ASG Terminate] -->|Lifecycle Hook| B

- id: q378
  type: multiple_choice
  question: |
    A real-time game uses UDP and needs to store non-relational gamer scores that scale without intervention.
    Which solution should be recommended?
  options:
    - text: Use a Network Load Balancer (NLB) for traffic and Amazon DynamoDB on-demand for storage.
      is_correct: true
    - text: Use an Application Load Balancer (ALB) and Amazon RDS.
      is_correct: false
    - text: Use AWS Global Accelerator and Amazon Aurora.
      is_correct: false
    - text: Use a Classic Load Balancer and MongoDB on EC2.
      is_correct: false
  explanation: |
    Correct: NLB is required for UDP traffic. DynamoDB on-demand scales automatically to handle any amount of data and traffic without manual intervention.
    Incorrect:
      - ALB does not support UDP.
      - Aurora/RDS are relational and require more scaling management compared to DynamoDB on-demand.
  diagram: |
    graph TD
      A[UDP Traffic] -->|NLB| B[DynamoDB On-Demand]
      B -->|Store Scores| C[Non-Relational Data]

- id: q379
  type: multiple_choice
  question: |
    A Lambda function experiences high latency because it loads many libraries and connects to RDS. The company wants the lowest latency with the fewest changes.
    Which solution meets this?
  options:
    - text: Configure provisioned concurrency for the Lambda function.
      is_correct: true
    - text: Rewrite the Lambda function in a faster language like Go.
      is_correct: false
    - text: Increase the Lambda function's timeout.
      is_correct: false
    - text: Use an RDS Read Replica.
      is_correct: false
  explanation: |
    Correct: Provisioned concurrency keeps Lambda functions "warm" and pre-initialized, eliminating "cold start" latency caused by loading libraries and establishing connections.
    Incorrect:
      - Rewriting code is a significant change.
      - Increasing timeout doesn't reduce latency.
      - Read Replicas help with query time but not with the initial connection/library loading time of the Lambda.
  diagram: |
    graph TD
      A[Lambda] -->|Provisioned Concurrency| B[Warm Instances]
      B -->|Low Latency| C[RDS]

- id: q380
  type: multiple_choice
  question: |
    A company is migrating its on-premises workload to the AWS Cloud. The company already uses several Amazon EC2 instances and Amazon RDS DB instances. The company wants a solution that automatically starts and stops the EC2 instances and DB instances outside of business hours. The solution must minimize cost and infrastructure maintenance.
    Which solution will meet these requirements?
  options:
    - text: Create an AWS Lambda function that will start and stop the EC2 instances and DB instances. Configure Amazon EventBridge to invoke the Lambda function on a schedule.
      is_correct: false
    - text: Use an EC2 instance running a cron job to execute AWS CLI commands to start and stop the instances.
      is_correct: false
    - text: Configure AWS Systems Manager State Manager to start and stop the instances based on a tag-based schedule.
      is_correct: false
    - text: Use the AWS Instance Scheduler on AWS Solutions to manage the start and stop operations.
      is_correct: true
  explanation: |
    Correct: While you can build a custom solution using Lambda and EventBridge, the AWS Instance Scheduler is a "ready-to-deploy" AWS Solution that provides a higher level of abstraction and automation with less manual coding and maintenance..
    Incorrect:
  diagram: |
    graph LR
      subgraph "AWS Solution: Instance Scheduler"
          EB[EventBridge Scheduler] -->|Triggers every N mins| LB[Lambda Function]
          LB -->|Checks Schedules| DDB[DynamoDB Table]
      end
      subgraph "Your Workload"
          LB -->|Start/Stop| EC2[EC2 Instances]
          LB -->|Start/Stop| RDS[RDS Databases]
          EC2 -.->|Identified by| Tags[Resource Tags]
          RDS -.->|Identified by| Tags
      end
      style EB fill:#FF9900,stroke:#232F3E,color:white
      style LB fill:#FF9900,stroke:#232F3E,color:white
      style DDB fill:#402770,stroke:#232F3E,color:white
      style EC2 fill:#F58536,stroke:#232F3E,color:white
      style RDS fill:#3B48CC,stroke:#232F3E,color:white

- id: q381
  type: multiple_choice
  question: |
    A three-tier web application with a PostgreSQL database storing document metadata. Documents are in S3. The monthly reporting process takes hours and involves relational queries. The process must not prevent document modifications.
    Which solution will speed up the reporting process with the LEAST amount of change to the application code?
  options:
     - text: Set up a new Amazon Aurora PostgreSQL DB cluster that includes an Aurora Replica. Issue queries to the Aurora Replica to generate the reports.
       is_correct: true
     - text: Migrate the metadata to Amazon DynamoDB and use global secondary indexes for reporting.
       is_correct: false
     - text: Use Amazon Athena to query the metadata directly from the PostgreSQL database using Federated Query.
       is_correct: false
     - text: Increase the instance size of the existing PostgreSQL database during the reporting window.
       is_correct: false
  explanation: |
    Correct: Aurora Replicas allow offloading of complex read-only queries from the primary writer. Since Aurora is PostgreSQL-compatible, this requires minimal code changes (just changing the connection endpoint for reports).
    Incorrect:
      - Migrating to DynamoDB requires a complete rewrite of the application's data layer.
      - Athena Federated Query is useful but typically slower for complex relational reporting than a native RDS replica.
      - Scaling up the primary instance still risks contention between writes and long-running reporting queries.
  diagram: |
    graph TD
      A[Application] -->|Writes| B[Aurora Primary]
      C[Reporting] -->|Reads| D[Aurora Replica]

- id: q382
  type: multiple_choice
  question: |
    A three-tier application ingests sensor data through a Network Load Balancer (NLB), then to EC2 web tier, then EC2 app tier, then a database.
    What should a solutions architect do to improve the security of the data in transit?
  options:
    - text: Configure a TLS listener. Deploy the server certificate on the NLB.
      is_correct: true
    - text: Encrypt the EBS volumes used by the EC2 instances.
      is_correct: false
    - text: Use an AWS Key Management Service (AWS KMS) key to encrypt the database connections.
      is_correct: false
    - text: Enable VPC Flow Logs to monitor the encrypted traffic.
      is_correct: false
  explanation: |
    Correct: Configuring a TLS listener on the NLB ensures that traffic from the user to the load balancer is encrypted (Encryption in Transit).
    Incorrect:
      - EBS encryption protects data at rest, not in transit.
      - KMS is used to manage keys, but it doesn't natively encrypt "connections" without TLS implementation.
      - VPC Flow Logs are for monitoring and do not provide encryption.
  diagram: |
    graph TD
      A[User] -->|TLS| B[NLB]
      B -->|Internal| C[EC2 Web Tier]
      C -->|Internal| D[EC2 App Tier]
      D -->|Internal| E[Database]

- id: q383
  type: multiple_choice
  question: |
    A company is deploying a public web app (EC2) and database (RDS MySQL). It must be secure for global customers with dynamic IPs.
    How should security groups be configured?
  options:
    - text: Configure the web server security group to allow inbound 443 from 0.0.0.0/0. Configure the DB security group to allow 3306 from the web server security group.
      is_correct: true
    - text: Allow 443 and 3306 from 0.0.0.0/0 on all security groups.
      is_correct: false
    - text: Allow 443 from the customer's specific IP addresses and 3306 from 0.0.0.0/0.
      is_correct: false
    - text: Use a Network ACL to allow 3306 and 443 from the entire VPC CIDR.
      is_correct: false
  explanation: |
    Correct: Allowing public access (0.0.0.0/0) to the web server is necessary for global customers. Restricting the database to only the web servers follows the principle of least privilege.
    Incorrect:
      - Exposing the database (3306) to the whole world is a major security risk.
      - Dynamic IPs mean you cannot restrict the web tier to specific customer IP addresses.
  diagram: |
    graph TD
        subgraph "INTERNET"
            USER((Usuário Global))
        end

        subgraph "VPC - AWS CLOUD"
            subgraph "Public Subnet"
                SG_WEB["Security Group: SG-Web-Server"]
                EC2[Instância EC2 - Web App]
            end

            subgraph "Private Subnet"
                SG_DB["Security Group: SG-Database"]
                RDS[RDS MySQL]
            end
        end

        %% Regras de Tráfego
        USER -- "Porta: 443 (HTTPS)<br/>Origem: 0.0.0.0/0" --> SG_WEB
        SG_WEB --> EC2
        
        EC2 -- "Porta: 3306 (MySQL)<br/>Origem: SG-Web-Server" --> SG_DB
        SG_DB --> RDS

        %% Estilos
        style SG_WEB fill:#e1f5fe,stroke:#000,stroke-dasharray: 5 5
        style SG_DB fill:#ffebee,stroke:#000,stroke-dasharray: 5 5
        style RDS fill:#fff
        style EC2 fill:#fff

- id: q384
  type: multiple_choice
  question: |
    An application needs a highly available, POSIX-compliant storage layer that is shareable across multiple AZs. Data is frequent for 30 days, then infrequent.
    Which solution is MOST cost-effective?
  options:
    - text: Use the Amazon Elastic File System (Amazon EFS) Standard storage class. Create a lifecycle management policy to move infrequently accessed data to EFS Standard-Infrequent Access (EFS Standard-IA).
      is_correct: true
    - text: Use Amazon EBS volumes with Multi-Attach enabled across all instances.
      is_correct: false
    - text: Use Amazon S3 with an S3 File Gateway to provide POSIX compatibility.
      is_correct: false
    - text: Deploy a clustered file system like Lustre on EC2 instances using EBS.
      is_correct: false
  explanation: |
    Correct: EFS is natively POSIX-compliant, shareable across multiple instances/AZs, and its Lifecycle Management feature automatically optimizes costs for older data.
    Incorrect:
      - EBS Multi-Attach is limited to a single AZ and requires specific cluster-aware file systems.
      - S3 File Gateway provides an interface but isn't as natively POSIX-compliant for complex application logic as EFS.
      - Self-managed clusters on EC2 increase operational overhead significantly.
  diagram: |
    graph TD
      A[Multi-AZ Instances] -->|POSIX| B[EFS Standard]
      B -->|Lifecycle| C[EFS Standard-IA]

- id: q385
  type: multiple_choice
  question: |
    VPC Design: Public subnets for ALB, Private for Web (HTTPS), Private for MySQL. ALB security group allows 443 from 0.0.0.0/0.
    Which additional configuration strategy follows the principle of least privilege?
  options:
    - text: Create a security group for the web servers and allow port 443 from the load balancer. Create a security group for the MySQL servers and allow port 3306 from the web servers security group.
      is_correct: true
    - text: Create a security group for the web servers and allow port 443 from 0.0.0.0/0.
      is_correct: false
    - text: Configure the Network ACLs to allow all traffic between the public and private subnets.
      is_correct: false
    - text: Allow port 3306 on the MySQL security group from the ALB security group.
      is_correct: false
  explanation: |
    Correct: This "chaining" of security groups ensures that only the ALB can talk to the Web servers, and only the Web servers can talk to the Database.
    Incorrect:
      - Allowing 443 from 0.0.0.0/0 on the web servers bypasses the ALB's security layer.
      - Allowing the ALB to talk directly to MySQL violates the 3-tier separation and least privilege.
      - Network ACLs are broad and should not replace security group rules for instance-level security.
  diagram: |
    graph TD
      A[ALB SG] -->|443| B[Web SG]
      B -->|3306| C[MySQL SG]

- id: q386
  type: multiple_choice
  question: |
    An ecommerce application's backend tier frequently requests identical datasets from an RDS MySQL database, causing slowdowns.
    Which action should be taken to improve performance?
  options:
    - text: Implement Amazon ElastiCache to cache the large datasets.
      is_correct: true
    - text: Migrate the database to Amazon Redshift for faster querying.
      is_correct: false
    - text: Use RDS Read Replicas to handle the identical queries.
      is_correct: false
    - text: Increase the IOPS on the RDS EBS volume.
      is_correct: false
  explanation: |
    Correct: In-memory caching with ElastiCache (Redis or Memcached) is the most effective way to handle frequent, identical read requests, reducing the load on the database.
    Incorrect:
      - Redshift is for OLAP/Analytical workloads, not for real-time application caching.
      - Read Replicas help with scaling read volume, but identical queries are still processed by the DB engine; a cache avoids the DB engine entirely.
      - Increasing IOPS doesn't solve the inefficiency of repeated identical queries.
  diagram: |
    graph TD
      A[Backend Tier] -->|Cache| B[ElastiCache]
      B -->|Fallback| C[RDS MySQL]

- id: q387
  type: multiple_choice
  question: |
    A deployment engineer will use CloudFormation to create resources. A solutions architect wants to follow the principle of least privilege.
    Which combination of actions should be taken? (Choose two.)
  options:
    - text: Create a new IAM user for the deployment engineer and add the IAM user to a group that allows AWS CloudFormation actions only.
      is_correct: true
    - text: Create an IAM role for the deployment engineer to explicitly define the permissions specific to the AWS CloudFormation stack and launch stacks using that IAM role.
      is_correct: true
    - text: Grant the engineer AdministratorAccess so they can create any resource defined in the template.
      is_correct: false
    - text: Use a Service Control Policy (SCP) to limit the engineer's actions across the entire organization.
      is_correct: false
    - text: Provide the engineer with the root account credentials for the deployment.
      is_correct: false
  explanation: |
    Correct: Limiting the user to CloudFormation actions and using a "Service Role" for the stack ensures the engineer can only perform deployments and the stack can only create the specific resources allowed by its role.
    Incorrect:
      - AdministratorAccess is the opposite of least privilege.
      - SCPs are for account-level restrictions, not for granular job activities of a single user.
      - Root credentials should never be used for daily activities.
    diagram: |
      graph TD
        A[IAM User] -->|CloudFormation Actions| B[IAM Group]
        B -->|Assume| C[Service Role]
        C -->|Create| D[Stack Resources]

- id: q388
  type: multiple_choice
  question: |
    A two-tier app (Web in public, RDS in private) cannot connect to the database. Configurations are default. The database is running.
    What should a solutions architect recommend?
  options:
     - text: Add an inbound rule to the security group of the database tier’s RDS instance to allow traffic from the web tier's security group.
       is_correct: true
     - text: Modify the Route Table of the private subnet to include a route to the Internet Gateway.
       is_correct: false
     - text: Change the Web tier instances to be in the same private subnet as the database.
       is_correct: false
     - text: Attach an Elastic IP address to the RDS instance.
       is_correct: false
  explanation: |
    Correct: By default, security groups deny all inbound traffic. The database security group must be explicitly told to allow traffic from the web tier on the database port (e.g., 3306).
    Incorrect:
      - Private subnets should not have a direct route to an Internet Gateway.
      - Moving Web instances to a private subnet doesn't fix the security group issue and might break public access to the web tier.
      - RDS instances in private subnets should not have public/Elastic IPs.
  diagram: |
    graph TD
      A[Web Tier SG] -->|Allow| B[DB SG]
      B -->|Inbound Rule| C[RDS Instance]

- id: q389
  type: multiple_choice
  question: |
    A company runs a business reporting queries to run without impacting write operations on an RDS MySQL instance in a single AZ.
    Which solution meets these requirements?
  options:
     - text: Deploy RDS read replicas to process the business reporting queries.
       is_correct: true
     - text: Enable Multi-AZ on the existing RDS instance.
       is_correct: false
     - text: Use Amazon Athena to query the RDS database directly.
       is_correct: false
     - text: Move the database to an EC2 instance with high-performance EBS volumes.
       is_correct: false
  explanation: |
    Correct: Read replicas are the standard solution for offloading read-only reporting traffic from the primary writer instance.
    Incorrect:
      - Multi-AZ is for high availability; the standby instance cannot be queried.
      - Athena queries data in S3, not RDS (unless using specialized connectors that are more complex than a replica).
      - Moving to EC2 increases operational overhead and doesn't solve the write-contention issue unless replicas are also used.
  diagram: |
    graph TD
      A[Write Operations] -->|Primary| B[RDS Instance]
      C[Reporting Queries] -->|Read Replica| D[RDS Replica]

- id: q391
  type: multiple_choice
  question: |
    A company needs a backup strategy for a stateless web application (EC2 ASG) and RDS PostgreSQL. RPO is 2 hours.
    Which solution maximizes scalability and optimizes resource utilization?
  options:
     - text: Retain the latest Amazon Machine Images (AMIs) of the web and application tiers. Enable automated backups in Amazon RDS and use point-in-time recovery.
       is_correct: true
     - text: Take hourly snapshots of all EBS volumes.
       is_correct: false
     - text: Use AWS Backup to create a daily backup of all EC2 instances.
       is_correct: false
     - text: Replicate the EC2 instances to another region using AWS Elastic Disaster Recovery.
       is_correct: false
  explanation: |
    Correct: Since the web tier is stateless, an AMI is sufficient to redeploy the instances at any time. RDS automated backups provide the 2-hour RPO requirement via PITR.
    Incorrect:
      - Hourly snapshots of stateless instances are a waste of storage and resources.
      - Daily backups don't meet a 2-hour RPO if data were stored on the instances (though here they are stateless).
      - Cross-region replication is more expensive than needed for this specific RPO.
  diagram: |
    graph TD
      A[EC2 ASG] -->|AMI Backup| B[Latest AMI]
      C[RDS] -->|Automated Backups| D[PITR within 2h]

- id: q392
  type: multiple_choice
  question: |
    A company is deploying a public web app (EC2) and database (RDS MySQL). It must be secure for global customers with dynamic IPs.
    How should security groups be configured?
  options:
    - text: Configure the web server security group to allow inbound 443 from 0.0.0.0/0. Configure the DB security group to allow 3306 from the web server security group.
      is_correct: true
    - text: Allow 443 and 3306 from 0.0.0.0/0 on all security groups.
      is_correct: false
    - text: Allow 443 from the customer's specific IP addresses and 3306 from 0.0.0.0/0.
      is_correct: false
    - text: Use a Network ACL to allow 3306 and 443 from the entire VPC CIDR.
      is_correct: false
  explanation: |
    Correct: Allowing public access (0.0.0.0/0) to the web server is necessary for global customers. Restricting the database to only the web servers follows the principle of least privilege.
    Incorrect:
      - Exposing the database (3306) to the whole world is a major security risk.
      - Dynamic IPs mean you cannot restrict the web tier to specific customer IP addresses.
  diagram: |
    graph TD
      A[Global Customers] -->|443| B[Web SG]
      B -->|3306| C[DB SG]

- id: q393
  type: multiple_choice
  question: |
    A company stores customer audio files in S3. They need to transcribe the audio and redact personally identifiable information (PII).
    What should a solutions architect do?
  options:
     - text: Configure an Amazon Transcribe transcription job with PII redaction turned on. Invoke it via Lambda upon S3 upload.
       is_correct: true
     - text: Use Amazon Rekognition to identify the speakers and manually redact the text.
       is_correct: false
     - text: Use Amazon Comprehend to transcribe the audio files.
       is_correct: false
     - text: Send the audio to an Amazon EMR cluster for processing.
       is_correct: false
  explanation: |
    Correct: Amazon Transcribe has a built-in PII redaction feature specifically designed for this use case.
    Incorrect:
      - Rekognition is for image and video analysis, not audio-to-text.
      - Comprehend is for Natural Language Processing (NLP) on text, it does not perform transcription of audio.
      - EMR is overkill and requires manual implementation of ASR and redaction logic.
  diagram: |
    graph TD
      A[S3 Upload] -->|Trigger| B[Lambda]
      B -->|Transcribe with PII Redaction| C[Amazon Transcribe]

- id: q394
  type: multiple_choice
  question: |
    An RDS MySQL instance uses a 2,000 GB gp3 volume. Performance degrades when IOPS exceed 20,000.
    What should a solutions architect do to improve performance?
  options:
     - text: Replace the volume with a Provisioned IOPS SSD (io2) volume.
       is_correct: true
     - text: Increase the size of the gp3 volume to 4,000 GB.
       is_correct: false
     - text: Change the database to a Multi-AZ deployment.
       is_correct: false
     - text: Enable EBS optimization on the RDS instance.
       is_correct: false
  explanation: |
    Correct: io2 volumes are designed for workloads requiring more than 16,000 IOPS with consistent, high performance.
    Incorrect:
      - gp3 has a maximum of 16,000 IOPS regardless of size (though throughput can scale).
      - Multi-AZ improves availability but doesn't increase the IOPS capacity of the primary volume.
      - RDS instances are EBS-optimized by default for the latest generations.
  diagram: |
    graph TD
      A[RDS Instance] -->|Replace| B[io2 Volume]
      B -->|High IOPS| C[Improved Performance]

- id: q395
  type: multiple_choice
  question: |
    A solutions architect needs to identify which IAM user made specific configuration changes to security groups last week.
    Which service should be used?
  options:
     - text: AWS CloudTrail
       is_correct: true
     - text: Amazon Inspector
       is_correct: false
     - text: AWS Config
       is_correct: false
     - text: Amazon CloudWatch Logs
       is_correct: false
  explanation: |
    Correct: CloudTrail logs all API calls made in an AWS account, including who made the call, when, and from where.
    Incorrect:
      - Inspector is for vulnerability scanning on instances.
      - AWS Config tracks resource changes over time but CloudTrail is the primary tool for auditing "who" performed the action.
      - CloudWatch Logs tracks application logs, not account-level API activity.
    diagram: |
      graph TD
        A[IAM User] -->|API Call| B[CloudTrail]
        B -->|Log| C[Security Group Changes]

- id: q396
  type: multiple_choice
  question: |
    An EC2 instance runs a DNS service and wants to protect against DDoS attacks.
    What should a solutions architect do?
  options:
     - text: Subscribe to AWS Shield Advanced. Add the accelerator as a resource to protect.
       is_correct: true
     - text: Enable AWS WAF on the Global Accelerator.
       is_correct: false
     - text: Use an Amazon CloudFront distribution instead of Global Accelerator.
       is_correct: false
     - text: Configure a Security Group to block all traffic except from known users.
       is_correct: false
  explanation: |
    Correct: AWS Shield Advanced provides enhanced DDoS protection for resources like Global Accelerator, including 24/7 access to the Shield Response Team.
    Incorrect:
      - WAF is for Layer 7 (HTTP/HTTPS) attacks; Global Accelerator is often used for Layer 4 (UDP/TCP) where Shield is more appropriate.
      - CloudFront doesn't support the raw UDP/TCP protocols often needed for a custom DNS service as well as Global Accelerator does.
  diagram: |
    graph TD
      A[DNS Service] -->|Global Accelerator| B[AWS Shield Advanced]

- id: q397
  type: multiple_choice
  question: |
    A daily job filters 10 GB S3 objects, taking up to an hour. CPU/Memory usage is constant and known. The goal is to minimize operational effort.
    Which solution meets this?
  options:
     - text: Create an Amazon ECS cluster with an AWS Fargate launch type. Schedule the task using Amazon EventBridge.
       is_correct: true
     - text: Run the job as an AWS Lambda function triggered by S3.
       is_correct: false
     - text: Use an EC2 instance with a cron job.
       is_correct: false
     - text: Use an AWS Glue ETL job.
       is_correct: false
  explanation: |
    Correct: Fargate is serverless, eliminating infrastructure management. EventBridge handles the scheduling. Since the job takes an hour, a container is better than Lambda.
    Incorrect:
      - Lambda has a maximum execution time of 15 minutes, which is insufficient.
      - EC2 requires manual maintenance, patching, and does not scale automatically.
      - AWS Glue is more suited for ETL processes and may introduce unnecessary complexity and cost.
  diagram: |
    graph TD
      A[Daily Job] -->|Trigger| B[ECS Fargate]
      B -->|Filter| C[S3 Objects]

- id: q425
  type: multiple_choice
  question: |
    A company needs 15,000 IOPS and wants to provision disk performance independent of storage capacity.
    Which EBS volume type is MOST cost-effective?
  options:
     - text: gp3
       is_correct: true
     - text: gp2
       is_correct: false
     - text: io1
       is_correct: false
     - text: st1
       is_correct: false
  explanation: |
    Correct: gp3 allows provisioning IOPS and Throughput independently of storage size, costing less than io1/io2 for up to 16,000 IOPS.
    Incorrect:
      - gp2 ties IOPS to storage size (3 IOPS/GB), requiring a huge disk for 15,000 IOPS.
      - io1 is much more expensive per IOPS.
      - st1 is HDD and doesn't achieve high IOPS.
  diagram: |
    graph TD
      A[Application] -->|15,000 IOPS| B[gp3 Volume]