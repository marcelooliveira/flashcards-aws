questions:
  - id: q351
    type: multiple_choice
    question: |
      A company is moving its data management application to AWS. The company wants to transition to an event-driven architecture. The architecture needs to be more distributed and to use serverless concepts while performing the different aspects of the workflow. The company also wants to minimize operational overhead.
    options:
     - text: Build out the workflow in AWS Step Functions. Use Step Functions to create a state machine. Use the state machine to invoke AWS Lambda functions to process the workflow steps.
       is_correct: true
     - text: Deploy the application logic on Amazon EC2 instances. Use Amazon MQ to coordinate the message flow between instances.
       is_correct: false
     - text: Use an Amazon SQS queue to trigger an Amazon ECS task for each step of the workflow.
       is_correct: false
     - text: Implement a monolithic application on AWS Elastic Beanstalk and use local cron jobs for task scheduling.
       is_correct: false
    explanation: |
      Correct: AWS Step Functions allows you to coordinate the components of distributed applications using visual workflows. It is a fully managed service, which means you don't need to worry about operational overhead. AWS Lambda is a serverless compute service, and it automatically scales with the workload.
      Incorrect: 
        - EC2 and Amazon MQ require significant operational overhead for patching, scaling, and broker management.
        - ECS tasks, even on Fargate, involve more management (container images, task definitions) than simple Lambda functions for basic workflow steps.
        - A monolithic application on Elastic Beanstalk contradicts the goal of a distributed, event-driven architecture.



  - id: q352
    type: multiple_choice
    question: |
      A company is designing the network for an online multi-player game. The game requires low-latency UDP traffic between players and the game servers. The game servers are hosted in an Auto Scaling group of EC2 instances across multiple Availability Zones.
    options:
     - text: Use a Network Load Balancer (NLB) to distribute traffic to the game servers.
       is_correct: true
     - text: Use an Application Load Balancer (ALB) with UDP listener support.
       is_correct: false
     - text: Use Amazon Route 53 with a Latency routing policy directly to the EC2 instances.
       is_correct: false
     - text: Deploy an Amazon CloudFront distribution to cache the UDP packets at the edge.
       is_correct: false
    explanation: |
      Correct: The Network Load Balancer (NLB) operates at the transport layer (Layer 4) and supports UDP traffic, providing the low latency required for gaming applications.
      Incorrect: 
        - Application Load Balancers (ALB) only support Layer 7 protocols like HTTP and HTTPS; they do not support UDP.
        - Routing directly to EC2 instances via Route 53 bypasses the load balancing and health check benefits provided by a dedicated balancer.
        - CloudFront is primarily for HTTP/HTTPS content delivery; it does not support proxying generic UDP traffic for real-time gaming.

  - id: q353
    type: multiple_choice
    question: |
      A solutions architect is designing a backup strategy for a mission-critical database on Amazon RDS for PostgreSQL. The database must have a Recovery Point Objective (RPO) of less than 5 minutes and a Recovery Time Objective (RTO) of less than 10 minutes.
    options:
     - text: Enable Multi-AZ deployment for the RDS instance.
       is_correct: true
     - text: Configure automated backups with a 1-day retention period.
       is_correct: false
     - text: Create a Cross-Region Read Replica of the database.
       is_correct: false
     - text: Schedule a Lambda function to take manual snapshots every 5 minutes.
       is_correct: false
    explanation: |
      Correct: RDS Multi-AZ provides synchronous replication to a standby instance in a different AZ. Failover is automatic and typically completes in under 2 minutes, meeting the strict RTO/RPO requirements for high availability.
      Incorrect: 
        - Automated backups allow point-in-time recovery, but restoring a database from a backup takes significantly longer than 10 minutes (violating RTO).
        - Cross-Region replicas use asynchronous replication, which may have a lag exceeding 5 minutes, and promoting a replica is a manual process that takes time.
        - Manual snapshots every 5 minutes create high I/O overhead and do not provide an automated failover mechanism to meet the RTO.



  - id: q399
    type: multiple_choice
    question: |
      A company’s website is experiencing a large number of requests from a specific range of IP addresses. The security team suspects an HTTP flood attack. Which AWS service or feature should be used to mitigate this attack?
    options:
     - text: Use AWS WAF and create a rate-based rule to block IP addresses that exceed a specified request threshold.
       is_correct: true
     - text: Use Network ACLs to manually block the suspected IP ranges.
       is_correct: false
     - text: Enable AWS Shield Standard to automatically block the Layer 7 flood.
       is_correct: false
     - text: Set up an Amazon CloudWatch alarm to trigger a Lambda function that updates Security Groups.
       is_correct: false
    explanation: |
      Correct: AWS WAF rate-based rules automatically track the rate of requests from each IP address. If an IP exceeds a defined limit (e.g., 2000 requests in 5 minutes), WAF blocks that IP until the rate drops, effectively mitigating HTTP floods.
      Incorrect: 
        - Network ACLs are stateless and manual; they cannot dynamically react to request rates or inspect Layer 7 traffic patterns.
        - AWS Shield Standard protects against Layer 3 and 4 attacks (DDoS); it does not provide the granular Layer 7 filtering needed for HTTP floods.
        - Updating Security Groups via Lambda is too slow for an active flood and has limits on the number of rules allowed per group.

  - id: q400
    type: multiple_choice
    question: |
      A meteorological startup company has a custom web application to sell weather data to its users online. The company uses Amazon DynamoDB to store its data and wants to build a new service that sends an alert to the managers of four internal teams every time a new weather event is recorded. The company does not want this new service to affect the performance of the current application.
    options:
     - text: Enable Amazon DynamoDB Streams on the table. Use triggers to write to a single Amazon Simple Notification Service (Amazon SNS) topic to which the teams can subscribe.
       is_correct: true
     - text: Create a secondary index on the table and have a cron job on an EC2 instance scan the index every minute for changes.
       is_correct: false
     - text: Modify the application code to write to four different SQS queues, one for each internal team, after every database write.
       is_correct: false
     - text: Use AWS CloudTrail to monitor DynamoDB PutItem calls and trigger an SNS notification.
       is_correct: false
    explanation: |
      Correct: DynamoDB Streams capture a time-ordered sequence of item-level modifications. This is asynchronous and does not consume the table's Provisioned Throughput, ensuring the primary application's performance remains unaffected.
      Incorrect: 
        - Scanning an index frequently is inefficient, consumes read capacity, and introduces a delay in notifications.
        - Modifying the application to write to four SQS queues increases application complexity, latency, and creates a tight coupling between the app and the notification service.
        - CloudTrail logs data plane operations only if specifically configured, but it is meant for auditing and has a significant delay (up to 15 minutes), which is unsuitable for real-time alerts.