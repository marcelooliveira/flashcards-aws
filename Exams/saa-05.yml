  # Todos os diagramas já estão no mesmo nível de tag e não possuem parênteses nos colchetes.
questions:
  - id: q201
    type: multiple_choice
    question: |
      A company is developing a marketing communications service that targets mobile app users. The company needs to send its users confirmation messages with Short Message Service (SMS). The users must be able to reply to the SMS messages. The company must store the responses for a year for analysis.
    options:
     - text: Build an Amazon Pinpoint journey. Configure Amazon Pinpoint to send events to an Amazon Kinesis data stream for analysis and archiving.
       is_correct: true
     - text: Use Amazon Simple Notification Service (SNS) to send the SMS. Create an AWS Lambda function to poll the SNS topic for replies.
       is_correct: false
     - text: Configure an Amazon Connect instance to handle SMS messaging and store logs in an Amazon RDS database.
       is_correct: false
     - text: Use Amazon Simple Email Service (SES) with the SMS receiving capability enabled and store results in S3.
       is_correct: false
    explanation: |
      Correct: Amazon Pinpoint is specifically designed for multi-step marketing journeys and natively supports two-way SMS. Streaming events to Kinesis allows for long-term archiving in S3 or Redshift.
      Incorrect:
        - Amazon SNS is primarily for one-way push notifications; it does not support "replies" or conversational SMS flows as easily as Pinpoint.
        - Amazon Connect is a contact center service; while it handles chat, it is not the most efficient tool for mass marketing SMS campaigns.
        - Amazon SES is for email (Simple Email Service), not for SMS communication.

    diagram: |
      graph TD
        A[User] -->|SMS| B[Pinpoint]
        B -->|Reply| A
        B --> C[Kinesis]
        C --> D[S3/Redshift]

  - id: q202
    type: multiple_choice
    question: |
      A company is planning to move its data to an Amazon S3 bucket. The data must be encrypted when it is stored in the S3 bucket. Additionally, the encryption key must be automatically rotated every year.
    options:
     - text: Create an AWS Key Management Service (AWS KMS) customer managed key. Enable automatic key rotation. Set the S3 bucket�s default encryption behavior to use the customer managed KMS key. Move the data to the S3 bucket.
       is_correct: true
     - text: Use Amazon S3 managed keys (SSE-S3) and configure the S3 bucket to rotate the keys annually in the S3 console.
       is_correct: false
     - text: Encrypt the data locally using a PGP key before uploading to S3. Set up a Cron job on an EC2 instance to rotate the key.
       is_correct: false
     - text: Use AWS Secrets Manager to store the encryption key and set a rotation schedule of 365 days.
       is_correct: false
    explanation: |
      Correct: AWS KMS Customer Managed Keys (CMK) support annual automatic rotation. Setting this as the default S3 encryption ensures all new objects are encrypted automatically.
      Incorrect:
        - SSE-S3 uses keys managed by S3; users cannot configure the rotation schedule for these keys.
        - Client-side encryption with manual PGP management involves high operational overhead and is not a managed AWS solution.
        - AWS Secrets Manager is for storing secrets (passwords, API keys), not for managing the underlying S3 server-side encryption process.

    diagram: |
      graph TD
        A[Data] --> B[S3 Bucket]
        B -->|KMS CMK| C[Key Rotation]

  - id: q203
    type: multiple_choice
    question: |
      The customers of a finance company request appointments with financial advisors by sending text messages... As the company expands, customers report that their meeting invitations are taking longer to arrive.
    options:
     - text: Add an Auto Scaling group for the application that sends meeting invitations. Configure the Auto Scaling group to scale based on the depth of the SQS queue.
       is_correct: true
     - text: Change the SQS queue to a FIFO (First-In-First-Out) queue to speed up message processing.
       is_correct: false
     - text: Vertically scale the EC2 instances by changing them to a larger instance type.
       is_correct: false
     - text: Implement DynamoDB Accelerator (DAX) to reduce the latency of meeting information writes.
       is_correct: false
    explanation: |
      Correct: Scaling based on the `ApproximateNumberOfMessagesVisible` metric (queue depth) ensures that as the backlog grows, more workers are added to process the invitations.
      Incorrect:
        - FIFO queues ensure order and deduplication but often have lower throughput (300-3000 TPS) than standard queues, which would not solve a delay caused by volume.
        - Vertical scaling has a hard limit and does not provide the elasticity needed for fluctuating demand like Auto Scaling does.
        - DAX improves read performance; the bottleneck here is the processing time in the queue, not the database write speed.

    diagram: |
      graph TD
        A[Customer] --> B[SQS Queue]
        B --> C[Auto Scaling Group]
        C --> D[Send Invitation]

  - id: q204
    type: multiple_choice
    question: |
      The company wants to make all the data available to various teams so that the teams can perform analytics. The solution must provide the ability to manage fine-grained permissions for the data and must minimize operational overhead.
    options:
     - text: Create a data lake by using AWS Lake Formation. Create an AWS Glue JDBC connection to Amazon RDS. Register the S3 bucket in Lake Formation. Use Lake Formation access controls to limit access.
       is_correct: true
     - text: Copy all data from RDS to the S3 bucket using AWS DataSync. Create different IAM roles for each team to access specific S3 prefixes.
       is_correct: false
     - text: Migrate the RDS data to an Amazon Redshift cluster. Use Redshift Spectrum to query the S3 data.
       is_correct: false
     - text: Use AWS Shield Advanced to protect the S3 bucket and RDS instance, and grant access via Bucket Policies.
       is_correct: false
    explanation: |
      Correct: Lake Formation simplifies the creation of a data lake and provides centralized, fine-grained access control (down to the column level), which is easier than managing complex IAM policies or bucket policies.
      Incorrect:
        - IAM roles for S3 prefixes are difficult to manage at scale for "fine-grained" access (like hiding specific columns).
        - Redshift is a powerful analytics tool, but setting it up involves higher operational overhead for management compared to Lake Formation.
        - AWS Shield is for DDoS protection and has no relevance to fine-grained data permissions for analytics.

    diagram: |
      graph TD
        A[RDS] --> B[Glue Connection]
        B --> C[S3 Bucket]
        C --> D[Lake Formation]
        D --> E[Teams]

  - id: q205
    type: multiple_choice
    question: |
      The company�s solutions architect creates a CloudFront distribution. The solutions architect must design the most cost-effective and resilient architecture for website hosting to serve as the CloudFront origin.
    options:
     - text: Create a private Amazon S3 bucket. Use an S3 bucket policy to allow access from a CloudFront origin access identity (OAI). Upload website content by using the AWS CLI.
       is_correct: true
     - text: Launch an EC2 instance in a public subnet. Install an Apache web server and upload the documents via SFTP.
       is_correct: false
     - text: Use an AWS Storage Gateway file gateway to sync the documents from on-premises directly to CloudFront.
       is_correct: false
     - text: Store the website in an Amazon EFS file system and mount it to the CloudFront distribution.
       is_correct: false
    explanation: |
      Correct: S3 is highly resilient (99.999999999% durability) and much more cost-effective than running a server. OAI ensures the bucket remains private while allowing CloudFront access.
      Incorrect:
        - EC2 requires patching, management, and is less resilient than S3 unless configured in a complex Multi-AZ Auto Scaling group.
        - Storage Gateway is used for hybrid storage, not as a direct origin for CloudFront.
        - CloudFront cannot mount EFS volumes directly; it requires an HTTP/HTTPS endpoint as an origin.

    diagram: |
      graph TD
        A[S3 Bucket] -->|OAI| B[CloudFront]
        B --> C[User]

  - id: q208
    type: multiple_choice
    question: |
      A company needs to move data from an Amazon EC2 instance to an Amazon S3 bucket. The company must ensure that no API calls and no data are routed through public internet routes. Only the EC2 instance can have access to upload data to the S3 bucket.
    options:
     - text: Create an interface VPC endpoint for Amazon S3 in the subnet where the EC2 instance is located. Attach a resource policy to the S3 bucket to only allow the EC2 instance�s IAM role for access.
       is_correct: true
     - text: Use a NAT Gateway in the public subnet to route the traffic to the S3 public endpoint.
       is_correct: false
     - text: Set up an AWS Direct Connect connection between the VPC and the S3 service.
       is_correct: false
     - text: Configure a Site-to-Site VPN and route the S3 traffic through the virtual private gateway.
       is_correct: false
    explanation: |
      Correct: VPC Endpoints (Interface or Gateway) keep traffic within the AWS network. An Interface endpoint provides a private IP, and the bucket policy ensures only the specific IAM role can perform the upload.
      Incorrect:
        - NAT Gateways still route traffic over the public internet to reach the S3 service endpoint.
        - Direct Connect is for connecting on-premises data centers to AWS, not for traffic between an EC2 instance and S3 within the cloud.
        - VPN is for encrypted traffic over the internet; the requirement specifically asks that no data is routed through public internet routes.

    diagram: |
      graph TD
        A[EC2 Instance] -->|VPC Endpoint| B[S3 Bucket]

  - id: q209
    type: multiple_choice
    question: |
      An Application Load Balancer (ALB) will handle the load distribution. The architecture needs to support distributed session data management. The company is willing to make changes to code if needed.
    options:
     - text: Use Amazon ElastiCache to manage and store session data.
       is_correct: true
     - text: Enable sticky sessions (session affinity) on the Application Load Balancer.
       is_correct: false
     - text: Store session data in the Amazon EBS volumes attached to the EC2 instances.
       is_correct: false
     - text: Replicate session data across instances using a mesh network of EC2 instances.
       is_correct: false
    explanation: |
      Correct: Moving session data to a centralized store like ElastiCache (Redis or Memcached) allows the EC2 instances to be truly stateless, enabling them to scale up and down without users losing their sessions.
      Incorrect:
        - Sticky sessions keep a user on one specific instance, but if that instance scales down or fails, the session data is lost.
        - EBS volumes are attached to specific instances; session data wouldn't be accessible to other instances in the Auto Scaling group.
        - A mesh network for replication is extremely complex to manage and prone to synchronization issues compared to a managed cache.

    diagram: |
      graph TD
        A[User] --> B[ALB]
        B --> C[EC2 Instances]
        C --> D[ElastiCache]

  - id: q211
    type: multiple_choice
    question: |
      A solutions architect must provide the quickest solution for identifying all of the tagged components.
    options:
     - text: Run a query with the AWS Resource Groups Tag Editor to report on the resources globally with the application tag.
       is_correct: true
     - text: Use the AWS CLI to run the `describe-instances` command for every region and filter by tag.
       is_correct: false
     - text: Create a custom AWS Config rule to alert on all resources that have the "application" tag.
       is_correct: false
     - text: Use the AWS Billing and Cost Management console to view the cost allocation tags.
       is_correct: false
    explanation: |
      Correct: Tag Editor is a global tool specifically designed to find and manage resources across regions based on their tags in a single view.
      Incorrect:
        - Running CLI commands for every region is time-consuming and manual (not the "quickest").
        - AWS Config is for compliance monitoring, not for generating a quick report of existing resources.
        - Cost allocation tags show financial data, but they don't provide a comprehensive list of all technical resource components.

    diagram: |
      graph TD
        A[Tag Editor] --> B[Resources]
        B --> C[Application Tag]

  - id: q213
    type: multiple_choice
    question: |
      The company must implement proper traffic filtering to protect its Application Load Balancer (ALB) against common application-level attacks, such as cross-site scripting or SQL injection.
    options:
     - text: Configure AWS WAF rules and associate them with the ALB.
       is_correct: true
     - text: Deploy an Amazon GuardDuty agent on the EC2 instances to block malicious traffic.
       is_correct: false
     - text: Use Network ACLs to block port 80 and 443 traffic from unknown IP addresses.
       is_correct: false
     - text: Implement an Amazon CloudFront distribution and set up a security group on S3.
       is_correct: false
    explanation: |
      Correct: AWS WAF is the standard tool for filtering Layer 7 attacks (SQLi, XSS) and integrates directly with the ALB.
      Incorrect:
        - GuardDuty is a threat detection service, not a prevention firewall; it doesn't block SQLi in real-time.
        - Network ACLs operate at Layer 4 (IP/Port) and cannot inspect the payload of a request to detect SQL injection.
        - Security groups on S3 don't protect an ALB/EC2-based application from web exploits.

    diagram: |
      graph TD
        A[User] --> B[ALB]
        B -->|WAF| C[App]

  - id: q220
    type: multiple_choice
    question: |
      Which compute service should the solutions architect have the API invoke to deliver the requirements at the lowest cost?
    options:
     - text: An AWS Lambda function
       is_correct: true
     - text: An Amazon EC2 instance in an Auto Scaling group with a minimum capacity of 1.
       is_correct: false
     - text: An Amazon ECS task running on AWS Fargate.
       is_correct: false
     - text: An Amazon EC2 Spot Instance.
       is_correct: false
    explanation: |
      Correct: Since the requests are infrequent (hours can pass without one), Lambda's pay-per-execution model is the cheapest. You pay $0 when the API is not being used.
      Incorrect:
        - EC2 instances incur costs even when idle. Even a "T" instance type costs more over a month than a few Lambda executions.
        - Fargate has a minimum billing duration and is more expensive for truly "sporadic" workloads.
        - Spot instances can be interrupted and still require a baseline management/runtime cost that Lambda avoids.

    diagram: |
      graph TD
        A[API] --> B[Lambda]
        B --> C[Process]