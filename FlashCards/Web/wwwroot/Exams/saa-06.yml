questions:
  - id: q251
    type: multiple_choice
    question: |
      An Amazon EC2 instance is located in a private subnet in a new VPC. This subnet does not have outbound internet access, but the EC2 instance needs the ability to download monthly security updates from an outside vendor.
    options:
     - text: Create a NAT gateway, and place it in a public subnet. Configure the private subnet route table to use the NAT gateway as the default route.
       is_correct: true
     - text: Attach an Internet Gateway directly to the private subnet and assign a public IP to the instance.
       is_correct: false
     - text: Create a Gateway VPC Endpoint for the outside vendor's website.
       is_correct: false
     - text: Use an Egress-Only Internet Gateway to allow IPv4 traffic to the outside vendor.
       is_correct: false
    explanation: |
      Correct: A NAT gateway allows instances in a private subnet to connect to services outside your VPC but prevents external services from initiating a connection with those instances. It must be placed in a public subnet with a route to an IGW.
      Incorrect: 
        - Attaching an IGW to a private subnet effectively makes it public, and the instance would need a public IP, which violates the "private subnet" architecture.
        - Gateway VPC Endpoints are only available for S3 and DynamoDB, not for arbitrary outside vendors.
        - Egress-Only Internet Gateways are specifically for IPv6 traffic, not IPv4.

  - id: q252
    type: multiple_choice
    question: |
      A solutions architect needs to design a system to store client case files. The files are core company assets and are important. The number of files will grow over time. The files must be simultaneously accessible from multiple application servers that run on Amazon EC2 instances. The solution must have built-in redundancy.
    options:
     - text: Amazon Elastic File System (Amazon EFS)
       is_correct: true
     - text: Amazon Elastic Block Store (Amazon EBS) with Multi-Attach enabled.
       is_correct: false
     - text: Amazon S3 with S3 File Gateway.
       is_correct: false
     - text: An EC2 instance configured as a Windows File Server with an attached EBS volume.
       is_correct: false
    explanation: |
      Correct: Amazon EFS provides a scalable, fully managed Network File System (NFS) that can be mounted by thousands of EC2 instances simultaneously across multiple Availability Zones, offering high durability and availability.
      Incorrect: 
        - EBS Multi-Attach is limited to specific instance types (Nitro) and a small number of instances (up to 16), making it less scalable than EFS for "growing files."
        - S3 File Gateway is intended for hybrid cloud scenarios to bridge on-premises to S3; EFS is the native choice for multiple EC2 instances.
        - A single EC2 file server is a single point of failure and does not have built-in redundancy like EFS.



  - id: q253
    type: multiple_choice
    question: |
      A company is running a commercial Apache Hadoop cluster on Amazon EC2 instances. This cluster is being used to process large amounts of data every day. The data is stored in Amazon S3. The processing has been slow. A solutions architect needs to recommend a solution to improve the speed of the data processing.
    options:
     - text: Use Amazon EMR to run the Hadoop cluster. Use the EMR File System (EMRFS) to access the data in Amazon S3.
       is_correct: true
     - text: Migrate the data from S3 to Amazon EBS Provisioned IOPS SSD (io2) volumes.
       is_correct: false
     - text: Increase the size of the EC2 instances to the largest available instance type.
       is_correct: false
     - text: Enable S3 Transfer Acceleration on the bucket where the data is stored.
       is_correct: false
    explanation: |
      Correct: Amazon EMR is a managed cluster platform that simplifies running big data frameworks. EMRFS is optimized for S3 and provides features like consistent view, significantly improving performance over a self-managed Hadoop on EC2.
      Incorrect: 
        - Moving petabytes of data from S3 to EBS is cost-prohibitive and lacks the durability and shared accessibility of S3.
        - Scaling up EC2 instances (Vertical scaling) is expensive and doesn't solve the underlying bottleneck of data transfer and Hadoop management.
        - S3 Transfer Acceleration speeds up data uploads over long distances; it does not improve the internal processing speed of a Hadoop cluster.

  - id: q254
    type: multiple_choice
    question: |
      A company wants to build a business intelligence (BI) dashboard for its management. The company stores its data in an Amazon S3 bucket. The data is in CSV format. The company needs to query the data from the S3 bucket and use a BI tool to visualize the data.
    options:
     - text: Use Amazon Athena to query the data. Use Amazon QuickSight to create the dashboard.
       is_correct: true
     - text: Use Amazon Redshift Spectrum to query the data. Use AWS Glue to visualize the data.
       is_correct: false
     - text: Load the data into an Amazon RDS for MySQL database. Use Amazon CloudWatch to create the dashboard.
       is_correct: false
     - text: Use Amazon Kinesis Data Analytics to process the CSV and output to a Lambda-based dashboard.
       is_correct: false
    explanation: |
      Correct: Amazon Athena is a serverless query service that makes it easy to analyze data in S3 using standard SQL. Amazon QuickSight is the native AWS BI tool that integrates perfectly with Athena.
      Incorrect: 
        - AWS Glue is an ETL service, not a visualization/BI tool.
        - CloudWatch is for infrastructure metrics, not for business intelligence dashboards based on CSV data.
        - Kinesis Data Analytics is for streaming data; Athena is much more efficient and cost-effective for one-time or batch queries on static S3 data.



  - id: q255
    type: multiple_choice
    question: |
      A company has a multi-tier web application that runs on Amazon EC2 instances in an Auto Scaling group. The application stores its data in an Amazon RDS for MySQL DB instance. The company wants to improve the performance of the application by reducing the load on the database.
    options:
     - text: Use Amazon ElastiCache to cache the database queries.
       is_correct: true
     - text: Enable Multi-AZ on the RDS DB instance to distribute the read load.
       is_correct: false
     - text: Create an Aurora Read Replica and point the application's write traffic to it.
       is_correct: false
     - text: Use Amazon S3 to store the database's frequently accessed tables.
       is_correct: false
    explanation: |
      Correct: Amazon ElastiCache (Redis or Memcached) is an in-memory data store that reduces database load by caching the results of frequent, read-heavy queries.
      Incorrect: 
        - Multi-AZ is for high availability and disaster recovery; the standby instance does not accept read or write traffic.
        - Read Replicas are for read traffic; pointing write traffic to a replica is not supported and would not work.
        - S3 is object storage and cannot be used to store active relational database tables for performance improvement.

  - id: q256
    type: multiple_choice
    question: |
      A solutions architect is designing the storage for a new application. The application will store millions of small objects in Amazon S3. The objects will be accessed frequently for the first 30 days and then infrequently. The company wants to minimize the cost of storage while maintaining high availability.
    options:
     - text: Use an S3 Lifecycle policy to move the objects from S3 Standard to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days.
       is_correct: true
     - text: Use S3 Intelligent-Tiering to manage the objects automatically.
       is_correct: false
     - text: Store all objects in S3 One Zone-Infrequent Access (S3 One Zone-IA) to save costs.
       is_correct: false
     - text: Use S3 Glacier Instant Retrieval for all objects immediately upon upload.
       is_correct: false
    explanation: |
      Correct: S3 Standard-IA is the most cost-effective tier for data that is infrequently accessed but requires millisecond access when needed. Moving data after 30 days aligns with the requirement.
      Incorrect: 
        - S3 Intelligent-Tiering has a monitoring and automation charge per object. For "millions of small objects," this fee can exceed the storage savings.
        - S3 One Zone-IA does not meet the "high availability" requirement because it stores data in only one AZ.
        - S3 Glacier Instant Retrieval is more expensive than S3 Standard for the first 30 days of frequent access.

  - id: q299
    type: multiple_choice
    question: |
      A company is using a cluster of Amazon EC2 instances to run a high performance computing (HPC) workload. The workload requires low-latency, high-throughput network communication between the instances.
    options:
     - text: Use an Elastic Fabric Adapter (EFA) for each EC2 instance in the cluster. Place the instances in a cluster placement group.
       is_correct: true
     - text: Use a Transit Gateway to connect the instances across different VPCs.
       is_correct: false
     - text: Enable Enhanced Networking using an Elastic Network Adapter (ENA) and use a partition placement group.
       is_correct: false
     - text: Use Amazon Route 53 with a latency-based routing policy to direct traffic between instances.
       is_correct: false
    explanation: |
      Correct: EFA is a network interface for Amazon EC2 instances that enables customers to run HPC applications requiring high levels of inter-node communication at scale. A Cluster Placement Group ensures the instances are physically close to minimize latency.
      Incorrect: 
        - Transit Gateway adds a hop and increase latency, which is unsuitable for HPC.
        - Partition placement groups are for distributed workloads like Hadoop/HDFS to prevent correlated failures; they don't minimize latency as well as Cluster groups.
        - Route 53 is for DNS; it does not improve the physical network performance between EC2 instances.



  - id: q300
    type: multiple_choice
    question: |
      A company needs to migrate a legacy application from an on-premises data center to the AWS Cloud because of hardware capacity constraints. The application runs 24 hours a day, 7 days a week. The application’s database storage continues to grow over time.
    options:
     - text: Migrate the application layer to Amazon EC2 Reserved Instances. Migrate the data storage layer to Amazon Aurora Reserved Instances.
       is_correct: true
     - text: Use On-Demand EC2 instances for the application and RDS for MySQL with magnetic storage.
       is_correct: false
     - text: Migrate to AWS Lambda to handle the application logic and use DynamoDB with Provisioned Capacity.
       is_correct: false
     - text: Use Amazon Lightsail to host both the application and the database to simplify management.
       is_correct: false
    explanation: |
      Correct: Since the application runs 24/7, Reserved Instances (RI) provide significant cost savings (up to 72%) over On-Demand. Aurora is ideal for growing databases as it automatically scales storage up to 128TB.
      Incorrect: 
        - On-Demand instances are the most expensive way to run a 24/7 workload. Magnetic storage is legacy and has very poor performance.
        - Lambda is better for intermittent or event-driven workloads; for a legacy app running 24/7, refactoring to serverless might be too complex and not necessarily cheaper.
        - Lightsail is for simple, small-scale applications and does not offer the scaling or enterprise features of EC2 and Aurora for a growing database.